{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1lDgHHIdL_QkWRIttYM1jjCAWlyLosxyT","timestamp":1679601770070}],"authorship_tag":"ABX9TyOjhryRVFowwwtqmigPBz5V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XwsMtFzSXcUb"},"outputs":[],"source":["# TensorFlow and tf.keras\n","import tensorflow as tf\n","\n","# Helper libraries\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["mnist = tf.keras.datasets.mnist"],"metadata":{"id":"40ncAmSBcN1Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"],"metadata":{"id":"RHd-Y2BPcRrX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images.shape"],"metadata":{"id":"FVHcOIr9dE9v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_labels"],"metadata":{"id":"dS2VYJaGdIVk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_images.shape"],"metadata":{"id":"PtsgOqcndIXz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Scale the data so that the pixel values are floating-point numbers from 0 to 1. You can do it manually or import and use the MinMaxScaler from the sklearn library (it would require you to reshape your data). After scaling, plot a few examples from the dataset."],"metadata":{"id":"T9jd0hPseOpE"}},{"cell_type":"code","source":[],"metadata":{"id":"bOpw_UutdIcY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Build a neural network with one hidden layer, 128 neurons. Use ReLu as the activation function in the hidden layers and softmax in the output layer. You may use tf.keras.Sequential or keras Functional API. If you have time, try model subclassing."],"metadata":{"id":"NAIHZ6kgetNT"}},{"cell_type":"code","source":[],"metadata":{"id":"i0QvW91scpSG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["How many parameters does your model have? What is the shape of each layer's output? Try to print out the network's structure and visualise it using Keras's functionality."],"metadata":{"id":"fO3cfPyPg5d5"}},{"cell_type":"code","source":[],"metadata":{"id":"V-vFUZhNgRN4","executionInfo":{"status":"ok","timestamp":1679989051543,"user_tz":-120,"elapsed":4,"user":{"displayName":"Mateusz Wasiluk","userId":"00556119438170176136"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As you can see, even though the structure of the network is quite simple, the number of parameters is definitely too large to tune them manually (although still quite small for deep learning standards). Fortunately, we have optimizers to do the work for us! "],"metadata":{"id":"TqeFwFAxigSi"}},{"cell_type":"markdown","source":["Compile the model with cross entropy as the loss function and Adam as the optimizer (write your code in such a way that you can hand-tune the optimizer's learning rate). Your model should report the prediction's accuracy as a classification metric. \n","\n","We're using cross entropy here, but Tensorflow provides several classes that implement this function. In which scenarios would we use BinaryCrossentropy, CategoricalCrossentropy and SparseCategoricalCrossentropy? When is it better to use numerical encoding of our labels, and when would we prefer (or have to) use one-hot encoding?\n","\n"],"metadata":{"id":"SisV4T3XgmzS"}},{"cell_type":"code","source":[],"metadata":{"id":"ZtX9hOpRn4sx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Use model.fit to train your network (on the train images and train labels). Try out different numbers of epochs to find out how long you need to train the model for optimal results. If you have time, you can experiment with different batch sizes, but start with 256.\n","\n","Model.fit returns a history object which serves as a log of your training process. Save it to a variable for later use.\n","\n","After traininig use model.evaluate to check your model's performance on the test dataset"],"metadata":{"id":"6d-Zjfjtn9QB"}},{"cell_type":"code","source":[],"metadata":{"id":"0BYYhbBgsr4H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Are you happy with the result? If the model performs worse on the test set it can be a symptom of overfitting. Later we will discuss how to mitigate this problem.\n","\n","Visualise how the value of the loss function and the accuracy changed during training. You can extract the data you need from the history variable which you created earlier. If you wish to get a deeper understanding of your model's behaviour, you can retrain it using an additional validation dataset - your model will be evaluated (but not trained!) on this data afer every epoch, and the results will be stored in history. You can use the test images for this purpose (not neccessarily the best practice), split your training data manually or using model.fit's functionality. \n","\n"],"metadata":{"id":"bJYGVdS1vLw2"}},{"cell_type":"code","source":["\n"],"metadata":{"id":"y72Srv56uCkr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now that we have a trained model, it's time to actually use it for prediction. You can call the model directly on the test images, or use the model.predict method. "],"metadata":{"id":"LxcE9vRI30yv"}},{"cell_type":"code","source":[],"metadata":{"id":"dsX-TRE96AEU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As you can see, the model returned a vector of 10 numbers for each image. Because we used the softmax function in the last layer, the elements of each such vector sum up to 1 and so we can interpret them as probability values. For example, if the result is [0.9, 0.1, 0,0,0,0,0,0,0,0] it means that the network is 90% sure that the image depicts a zero and 10% sure that it's a one. Imnvestigate your network's predictions. Can you see any particular patterns? For example, do some classes seem to be more difficult to classify than the others? You're free to experiment with different ways of data analysis and visualisation.\n","\n","As the last step, transform your network's predictions from probability vectors to individual labels, so they are easier to use. Congratulations on a working model! "],"metadata":{"id":"i5Smrrwk6YqD"}},{"cell_type":"code","source":[],"metadata":{"id":"1irYuceZM8No"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Bonus task: If you've finished all the tasks, try to prepare a similar model for a different dataset. A convenient website with a lot of publicly-available datasets is Kaggle - take a look at the [particle identification dataset from the CMS experiment in CERN. ](https://www.kaggle.com/datasets/omidbaghchehsaraei/cern-subatomic-particles-dataset) Depending on the dataset, you may need to do extra preprocessing, for example scale the values in a different way or encode the non-numerical data. For this purpose, explore the functionalities of the Scikit-learn library. If the dataset is in the CSV format, use pandas to read it to a DataFrame object."],"metadata":{"id":"4OOkLtg8t5E2"}},{"cell_type":"code","source":[],"metadata":{"id":"Kp8x2CBr9h4t"},"execution_count":null,"outputs":[]}]}